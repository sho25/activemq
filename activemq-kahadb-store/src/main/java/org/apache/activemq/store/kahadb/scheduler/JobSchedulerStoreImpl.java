begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|scheduler
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FilenameFilter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|broker
operator|.
name|scheduler
operator|.
name|JobScheduler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|broker
operator|.
name|scheduler
operator|.
name|JobSchedulerStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|protobuf
operator|.
name|Buffer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|AbstractKahaDBStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|JournalCommand
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|KahaDBMetaData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|Visitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|data
operator|.
name|KahaAddScheduledJobCommand
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|data
operator|.
name|KahaDestroySchedulerCommand
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|data
operator|.
name|KahaRemoveScheduledJobCommand
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|data
operator|.
name|KahaRemoveScheduledJobsCommand
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|data
operator|.
name|KahaRescheduleJobCommand
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|data
operator|.
name|KahaTraceCommand
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|disk
operator|.
name|index
operator|.
name|BTreeVisitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|disk
operator|.
name|journal
operator|.
name|DataFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|disk
operator|.
name|journal
operator|.
name|Location
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|disk
operator|.
name|page
operator|.
name|Page
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|disk
operator|.
name|page
operator|.
name|PageFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|disk
operator|.
name|page
operator|.
name|Transaction
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|disk
operator|.
name|util
operator|.
name|VariableMarshaller
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|store
operator|.
name|kahadb
operator|.
name|scheduler
operator|.
name|legacy
operator|.
name|LegacyStoreReplayer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|util
operator|.
name|ByteSequence
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|activemq
operator|.
name|util
operator|.
name|IOHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/*  * @org.apache.xbean.XBean element="kahaDBJobScheduler"  */
end_comment

begin_class
specifier|public
class|class
name|JobSchedulerStoreImpl
extends|extends
name|AbstractKahaDBStore
implements|implements
name|JobSchedulerStore
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|JobSchedulerStoreImpl
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|JobSchedulerKahaDBMetaData
name|metaData
init|=
operator|new
name|JobSchedulerKahaDBMetaData
argument_list|(
name|this
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|MetaDataMarshaller
name|metaDataMarshaller
init|=
operator|new
name|MetaDataMarshaller
argument_list|(
name|this
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|JobSchedulerImpl
argument_list|>
name|schedulers
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|JobSchedulerImpl
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
name|File
name|legacyStoreArchiveDirectory
decl_stmt|;
comment|/**      * The Scheduler Token is used to identify base revisions of the Scheduler store.  A store      * based on the initial scheduler design will not have this tag in it's meta-data and will      * indicate an update is needed.  Later versions of the scheduler can also change this value      * to indicate incompatible store bases which require complete meta-data and journal rewrites      * instead of simpler meta-data updates.      */
specifier|static
specifier|final
name|UUID
name|SCHEDULER_STORE_TOKEN
init|=
name|UUID
operator|.
name|fromString
argument_list|(
literal|"57ed642b-1ee3-47b3-be6d-b7297d500409"
argument_list|)
decl_stmt|;
comment|/**      * The default scheduler store version.  All new store instance will be given this version and      * earlier versions will be updated to this version.      */
specifier|static
specifier|final
name|int
name|CURRENT_VERSION
init|=
literal|1
decl_stmt|;
annotation|@
name|Override
specifier|public
name|JobScheduler
name|getJobScheduler
parameter_list|(
specifier|final
name|String
name|name
parameter_list|)
throws|throws
name|Exception
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|JobSchedulerImpl
name|result
init|=
name|this
operator|.
name|schedulers
operator|.
name|get
argument_list|(
name|name
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
specifier|final
name|JobSchedulerImpl
name|js
init|=
operator|new
name|JobSchedulerImpl
argument_list|(
name|this
argument_list|)
decl_stmt|;
name|js
operator|.
name|setName
argument_list|(
name|name
argument_list|)
expr_stmt|;
name|getPageFile
argument_list|()
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|js
operator|.
name|createIndexes
argument_list|(
name|tx
argument_list|)
expr_stmt|;
name|js
operator|.
name|load
argument_list|(
name|tx
argument_list|)
expr_stmt|;
name|metaData
operator|.
name|getJobSchedulers
argument_list|()
operator|.
name|put
argument_list|(
name|tx
argument_list|,
name|name
argument_list|,
name|js
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|result
operator|=
name|js
expr_stmt|;
name|this
operator|.
name|schedulers
operator|.
name|put
argument_list|(
name|name
argument_list|,
name|js
argument_list|)
expr_stmt|;
if|if
condition|(
name|isStarted
argument_list|()
condition|)
block|{
name|result
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|pageFile
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|removeJobScheduler
parameter_list|(
specifier|final
name|String
name|name
parameter_list|)
throws|throws
name|Exception
block|{
name|boolean
name|result
init|=
literal|false
decl_stmt|;
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
specifier|final
name|JobSchedulerImpl
name|js
init|=
name|this
operator|.
name|schedulers
operator|.
name|remove
argument_list|(
name|name
argument_list|)
decl_stmt|;
name|result
operator|=
name|js
operator|!=
literal|null
expr_stmt|;
if|if
condition|(
name|result
condition|)
block|{
name|js
operator|.
name|stop
argument_list|()
expr_stmt|;
name|getPageFile
argument_list|()
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|metaData
operator|.
name|getJobSchedulers
argument_list|()
operator|.
name|remove
argument_list|(
name|tx
argument_list|,
name|name
argument_list|)
expr_stmt|;
name|js
operator|.
name|removeAll
argument_list|(
name|tx
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**      * Sets the directory where the legacy scheduler store files are archived before an      * update attempt is made.  Both the legacy index files and the journal files are moved      * to this folder prior to an upgrade attempt.      *      * @param directory      *      The directory to move the legacy Scheduler Store files to.      */
specifier|public
name|void
name|setLegacyStoreArchiveDirectory
parameter_list|(
name|File
name|directory
parameter_list|)
block|{
name|this
operator|.
name|legacyStoreArchiveDirectory
operator|=
name|directory
expr_stmt|;
block|}
comment|/**      * Gets the directory where the legacy Scheduler Store files will be archived if the      * broker is started and an existing Job Scheduler Store from an old version is detected.      *      * @return the directory where scheduler store legacy files are archived on upgrade.      */
specifier|public
name|File
name|getLegacyStoreArchiveDirectory
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|legacyStoreArchiveDirectory
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|legacyStoreArchiveDirectory
operator|=
operator|new
name|File
argument_list|(
name|getDirectory
argument_list|()
argument_list|,
literal|"legacySchedulerStore"
argument_list|)
expr_stmt|;
block|}
return|return
name|this
operator|.
name|legacyStoreArchiveDirectory
operator|.
name|getAbsoluteFile
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|load
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|opened
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|getJournal
argument_list|()
operator|.
name|start
argument_list|()
expr_stmt|;
try|try
block|{
name|loadPageFile
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnknownStoreVersionException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Can't start until store update is performed."
argument_list|)
expr_stmt|;
name|upgradeFromLegacy
argument_list|()
expr_stmt|;
comment|// Restart with the updated store
name|getJournal
argument_list|()
operator|.
name|start
argument_list|()
expr_stmt|;
name|loadPageFile
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Update from legacy Scheduler store completed successfully."
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Index corrupted. Recovering the index through journal replay. Cause: {}"
argument_list|,
name|t
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Index load failure"
argument_list|,
name|t
argument_list|)
expr_stmt|;
comment|// try to recover index
try|try
block|{
name|pageFile
operator|.
name|unload
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ignore
parameter_list|)
block|{                 }
if|if
condition|(
name|isArchiveCorruptedIndex
argument_list|()
condition|)
block|{
name|pageFile
operator|.
name|archive
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|pageFile
operator|.
name|delete
argument_list|()
expr_stmt|;
block|}
name|metaData
operator|=
operator|new
name|JobSchedulerKahaDBMetaData
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|pageFile
operator|=
literal|null
expr_stmt|;
name|loadPageFile
argument_list|()
expr_stmt|;
block|}
name|startCheckpoint
argument_list|()
expr_stmt|;
name|recover
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"{} started."
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|unload
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|opened
operator|.
name|compareAndSet
argument_list|(
literal|true
argument_list|,
literal|false
argument_list|)
condition|)
block|{
for|for
control|(
name|JobSchedulerImpl
name|js
range|:
name|this
operator|.
name|schedulers
operator|.
name|values
argument_list|()
control|)
block|{
try|try
block|{
name|js
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|pageFile
operator|!=
literal|null
operator|&&
name|pageFile
operator|.
name|isLoaded
argument_list|()
condition|)
block|{
name|metaData
operator|.
name|setState
argument_list|(
name|KahaDBMetaData
operator|.
name|CLOSED_STATE
argument_list|)
expr_stmt|;
if|if
condition|(
name|metaData
operator|.
name|getPage
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|pageFile
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|tx
operator|.
name|store
argument_list|(
name|metaData
operator|.
name|getPage
argument_list|()
argument_list|,
name|metaDataMarshaller
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|checkpointLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|metaData
operator|.
name|getPage
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|checkpointUpdate
argument_list|(
name|getCleanupOnStop
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|checkpointLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|checkpointThreadLock
init|)
block|{
if|if
condition|(
name|checkpointThread
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|checkpointThread
operator|.
name|join
argument_list|()
expr_stmt|;
name|checkpointThread
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{                     }
block|}
block|}
if|if
condition|(
name|pageFile
operator|!=
literal|null
condition|)
block|{
name|pageFile
operator|.
name|unload
argument_list|()
expr_stmt|;
name|pageFile
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|journal
operator|!=
literal|null
condition|)
block|{
name|journal
operator|.
name|close
argument_list|()
expr_stmt|;
name|journal
operator|=
literal|null
expr_stmt|;
block|}
name|metaData
operator|=
operator|new
name|JobSchedulerKahaDBMetaData
argument_list|(
name|this
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"{} stopped."
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|loadPageFile
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
specifier|final
name|PageFile
name|pageFile
init|=
name|getPageFile
argument_list|()
decl_stmt|;
name|pageFile
operator|.
name|load
argument_list|()
expr_stmt|;
name|pageFile
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|pageFile
operator|.
name|getPageCount
argument_list|()
operator|==
literal|0
condition|)
block|{
name|Page
argument_list|<
name|JobSchedulerKahaDBMetaData
argument_list|>
name|page
init|=
name|tx
operator|.
name|allocate
argument_list|()
decl_stmt|;
assert|assert
name|page
operator|.
name|getPageId
argument_list|()
operator|==
literal|0
assert|;
name|page
operator|.
name|set
argument_list|(
name|metaData
argument_list|)
expr_stmt|;
name|metaData
operator|.
name|setPage
argument_list|(
name|page
argument_list|)
expr_stmt|;
name|metaData
operator|.
name|setState
argument_list|(
name|KahaDBMetaData
operator|.
name|CLOSED_STATE
argument_list|)
expr_stmt|;
name|metaData
operator|.
name|initialize
argument_list|(
name|tx
argument_list|)
expr_stmt|;
name|tx
operator|.
name|store
argument_list|(
name|metaData
operator|.
name|getPage
argument_list|()
argument_list|,
name|metaDataMarshaller
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Page
argument_list|<
name|JobSchedulerKahaDBMetaData
argument_list|>
name|page
init|=
literal|null
decl_stmt|;
name|page
operator|=
name|tx
operator|.
name|load
argument_list|(
literal|0
argument_list|,
name|metaDataMarshaller
argument_list|)
expr_stmt|;
name|metaData
operator|=
name|page
operator|.
name|get
argument_list|()
expr_stmt|;
name|metaData
operator|.
name|setPage
argument_list|(
name|page
argument_list|)
expr_stmt|;
block|}
name|metaData
operator|.
name|load
argument_list|(
name|tx
argument_list|)
expr_stmt|;
name|metaData
operator|.
name|loadScheduler
argument_list|(
name|tx
argument_list|,
name|schedulers
argument_list|)
expr_stmt|;
for|for
control|(
name|JobSchedulerImpl
name|js
range|:
name|schedulers
operator|.
name|values
argument_list|()
control|)
block|{
try|try
block|{
name|js
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|JobSchedulerStoreImpl
operator|.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to load "
operator|+
name|js
operator|.
name|getName
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
argument_list|)
expr_stmt|;
name|pageFile
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|upgradeFromLegacy
parameter_list|()
throws|throws
name|IOException
block|{
name|journal
operator|.
name|close
argument_list|()
expr_stmt|;
name|journal
operator|=
literal|null
expr_stmt|;
try|try
block|{
name|pageFile
operator|.
name|unload
argument_list|()
expr_stmt|;
name|pageFile
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ignore
parameter_list|)
block|{}
name|File
name|storeDir
init|=
name|getDirectory
argument_list|()
operator|.
name|getAbsoluteFile
argument_list|()
decl_stmt|;
name|File
name|storeArchiveDir
init|=
name|getLegacyStoreArchiveDirectory
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Attempting to move old store files from {} to {}"
argument_list|,
name|storeDir
argument_list|,
name|storeArchiveDir
argument_list|)
expr_stmt|;
comment|// Move only the known store files, locks and other items left in place.
name|IOHelper
operator|.
name|moveFiles
argument_list|(
name|storeDir
argument_list|,
name|storeArchiveDir
argument_list|,
operator|new
name|FilenameFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|File
name|dir
parameter_list|,
name|String
name|name
parameter_list|)
block|{
if|if
condition|(
name|name
operator|.
name|endsWith
argument_list|(
literal|".data"
argument_list|)
operator|||
name|name
operator|.
name|endsWith
argument_list|(
literal|".redo"
argument_list|)
operator|||
name|name
operator|.
name|endsWith
argument_list|(
literal|".log"
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
block|}
argument_list|)
expr_stmt|;
comment|// We reset everything to clean state, then we can read from the old
comment|// scheduler store and replay the scheduled jobs into this one as adds.
name|getJournal
argument_list|()
operator|.
name|start
argument_list|()
expr_stmt|;
name|metaData
operator|=
operator|new
name|JobSchedulerKahaDBMetaData
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|pageFile
operator|=
literal|null
expr_stmt|;
name|loadPageFile
argument_list|()
expr_stmt|;
name|LegacyStoreReplayer
name|replayer
init|=
operator|new
name|LegacyStoreReplayer
argument_list|(
name|getLegacyStoreArchiveDirectory
argument_list|()
argument_list|)
decl_stmt|;
name|replayer
operator|.
name|load
argument_list|()
expr_stmt|;
name|replayer
operator|.
name|startReplay
argument_list|(
name|this
argument_list|)
expr_stmt|;
comment|// Cleanup after replay and store what we've done.
name|pageFile
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|tx
operator|.
name|store
argument_list|(
name|metaData
operator|.
name|getPage
argument_list|()
argument_list|,
name|metaDataMarshaller
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|checkpointUpdate
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|getJournal
argument_list|()
operator|.
name|close
argument_list|()
expr_stmt|;
name|getPageFile
argument_list|()
operator|.
name|unload
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|checkpointUpdate
parameter_list|(
name|Transaction
name|tx
parameter_list|,
name|boolean
name|cleanup
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Job Scheduler Store Checkpoint started."
argument_list|)
expr_stmt|;
comment|// reflect last update exclusive of current checkpoint
name|Location
name|lastUpdate
init|=
name|metaData
operator|.
name|getLastUpdateLocation
argument_list|()
decl_stmt|;
name|metaData
operator|.
name|setState
argument_list|(
name|KahaDBMetaData
operator|.
name|OPEN_STATE
argument_list|)
expr_stmt|;
name|tx
operator|.
name|store
argument_list|(
name|metaData
operator|.
name|getPage
argument_list|()
argument_list|,
name|metaDataMarshaller
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|pageFile
operator|.
name|flush
argument_list|()
expr_stmt|;
if|if
condition|(
name|cleanup
condition|)
block|{
specifier|final
name|TreeSet
argument_list|<
name|Integer
argument_list|>
name|completeFileSet
init|=
operator|new
name|TreeSet
argument_list|<
name|Integer
argument_list|>
argument_list|(
name|journal
operator|.
name|getFileMap
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|TreeSet
argument_list|<
name|Integer
argument_list|>
name|gcCandidateSet
init|=
operator|new
name|TreeSet
argument_list|<
name|Integer
argument_list|>
argument_list|(
name|completeFileSet
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"Last update: {}, full gc candidates set: {}"
argument_list|,
name|lastUpdate
argument_list|,
name|gcCandidateSet
argument_list|)
expr_stmt|;
if|if
condition|(
name|lastUpdate
operator|!=
literal|null
condition|)
block|{
name|gcCandidateSet
operator|.
name|remove
argument_list|(
name|lastUpdate
operator|.
name|getDataFileId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|metaData
operator|.
name|getJournalRC
argument_list|()
operator|.
name|visit
argument_list|(
name|tx
argument_list|,
operator|new
name|BTreeVisitor
argument_list|<
name|Integer
argument_list|,
name|Integer
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
name|List
argument_list|<
name|Integer
argument_list|>
name|keys
parameter_list|,
name|List
argument_list|<
name|Integer
argument_list|>
name|values
parameter_list|)
block|{
for|for
control|(
name|Integer
name|key
range|:
name|keys
control|)
block|{
if|if
condition|(
name|gcCandidateSet
operator|.
name|remove
argument_list|(
name|key
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Removed referenced file: {} from GC set"
argument_list|,
name|key
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isInterestedInKeysBetween
parameter_list|(
name|Integer
name|first
parameter_list|,
name|Integer
name|second
parameter_list|)
block|{
return|return
literal|true
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"gc candidates after reference check: {}"
argument_list|,
name|gcCandidateSet
argument_list|)
expr_stmt|;
comment|// If there are GC candidates then check the remove command location to see
comment|// if any of them can go or if they must stay in order to ensure proper recover.
comment|//
comment|// A log containing any remove commands must be kept until all the logs with the
comment|// add commands for all the removed jobs have been dropped.
if|if
condition|(
operator|!
name|gcCandidateSet
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|Integer
argument_list|,
name|List
argument_list|<
name|Integer
argument_list|>
argument_list|>
argument_list|>
name|removals
init|=
name|metaData
operator|.
name|getRemoveLocationTracker
argument_list|()
operator|.
name|iterator
argument_list|(
name|tx
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|orphans
init|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
while|while
condition|(
name|removals
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|boolean
name|orphanedRemove
init|=
literal|true
decl_stmt|;
name|Entry
argument_list|<
name|Integer
argument_list|,
name|List
argument_list|<
name|Integer
argument_list|>
argument_list|>
name|entry
init|=
name|removals
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// If this log is not a GC candidate then there's no need to do a check to rule it out
if|if
condition|(
name|gcCandidateSet
operator|.
name|contains
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
for|for
control|(
name|Integer
name|addLocation
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
if|if
condition|(
name|completeFileSet
operator|.
name|contains
argument_list|(
name|addLocation
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"A remove in log {} has an add still in existance in {}."
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|addLocation
argument_list|)
expr_stmt|;
name|orphanedRemove
operator|=
literal|false
expr_stmt|;
break|break;
block|}
block|}
comment|// If it's not orphaned than we can't remove it, otherwise we
comment|// stop tracking it it's log will get deleted on the next check.
if|if
condition|(
operator|!
name|orphanedRemove
condition|)
block|{
name|gcCandidateSet
operator|.
name|remove
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"All removes in log {} are orphaned, file can be GC'd"
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
name|orphans
operator|.
name|add
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// Drop all orphaned removes from the tracker.
for|for
control|(
name|Integer
name|orphan
range|:
name|orphans
control|)
block|{
name|metaData
operator|.
name|getRemoveLocationTracker
argument_list|()
operator|.
name|remove
argument_list|(
name|tx
argument_list|,
name|orphan
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|trace
argument_list|(
literal|"gc candidates after removals check: {}"
argument_list|,
name|gcCandidateSet
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|gcCandidateSet
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleanup removing the data files: "
operator|+
name|gcCandidateSet
argument_list|)
expr_stmt|;
block|}
name|journal
operator|.
name|removeDataFiles
argument_list|(
name|gcCandidateSet
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Job Scheduler Store Checkpoint complete."
argument_list|)
expr_stmt|;
block|}
comment|/**      * Adds a reference for the journal log file pointed to by the given Location value.      *      * To prevent log files in the journal that still contain valid data that needs to be      * kept in order to allow for recovery the logs must have active references.  Each Job      * scheduler should ensure that the logs are accurately referenced.      *      * @param tx      *      The TX under which the update is to be performed.      * @param location      *      The location value to update the reference count of.      *      * @throws IOException if an error occurs while updating the journal references table.      */
specifier|protected
name|void
name|incrementJournalCount
parameter_list|(
name|Transaction
name|tx
parameter_list|,
name|Location
name|location
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|logId
init|=
name|location
operator|.
name|getDataFileId
argument_list|()
decl_stmt|;
name|Integer
name|val
init|=
name|metaData
operator|.
name|getJournalRC
argument_list|()
operator|.
name|get
argument_list|(
name|tx
argument_list|,
name|logId
argument_list|)
decl_stmt|;
name|int
name|refCount
init|=
name|val
operator|!=
literal|null
condition|?
name|val
operator|.
name|intValue
argument_list|()
operator|+
literal|1
else|:
literal|1
decl_stmt|;
name|metaData
operator|.
name|getJournalRC
argument_list|()
operator|.
name|put
argument_list|(
name|tx
argument_list|,
name|logId
argument_list|,
name|refCount
argument_list|)
expr_stmt|;
block|}
comment|/**      * Removes one reference for the Journal log file indicated in the given Location value.      *      * The references are used to track which log files cannot be GC'd.  When the reference count      * on a log file reaches zero the file id is removed from the tracker and the log will be      * removed on the next check point update.      *      * @param tx      *      The TX under which the update is to be performed.      * @param location      *      The location value to update the reference count of.      *      * @throws IOException if an error occurs while updating the journal references table.      */
specifier|protected
name|void
name|decrementJournalCount
parameter_list|(
name|Transaction
name|tx
parameter_list|,
name|Location
name|location
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|logId
init|=
name|location
operator|.
name|getDataFileId
argument_list|()
decl_stmt|;
name|Integer
name|refCount
init|=
name|metaData
operator|.
name|getJournalRC
argument_list|()
operator|.
name|get
argument_list|(
name|tx
argument_list|,
name|logId
argument_list|)
decl_stmt|;
if|if
condition|(
name|refCount
operator|!=
literal|null
condition|)
block|{
name|int
name|refCountValue
init|=
name|refCount
decl_stmt|;
name|refCountValue
operator|--
expr_stmt|;
if|if
condition|(
name|refCountValue
operator|<=
literal|0
condition|)
block|{
name|metaData
operator|.
name|getJournalRC
argument_list|()
operator|.
name|remove
argument_list|(
name|tx
argument_list|,
name|logId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|metaData
operator|.
name|getJournalRC
argument_list|()
operator|.
name|put
argument_list|(
name|tx
argument_list|,
name|logId
argument_list|,
name|refCountValue
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**      * Updates the Job removal tracking index with the location of a remove command and the      * original JobLocation entry.      *      * The JobLocation holds the locations in the logs where the add and update commands for      * a job stored.  The log file containing the remove command can only be discarded after      * both the add and latest update log files have also been discarded.      *      * @param tx      *      The TX under which the update is to be performed.      * @param location      *      The location value to reference a remove command.      * @param removedJob      *      The original JobLocation instance that holds the add and update locations      *      * @throws IOException if an error occurs while updating the remove location tracker.      */
specifier|protected
name|void
name|referenceRemovedLocation
parameter_list|(
name|Transaction
name|tx
parameter_list|,
name|Location
name|location
parameter_list|,
name|JobLocation
name|removedJob
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|logId
init|=
name|location
operator|.
name|getDataFileId
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|removed
init|=
name|this
operator|.
name|metaData
operator|.
name|getRemoveLocationTracker
argument_list|()
operator|.
name|get
argument_list|(
name|tx
argument_list|,
name|logId
argument_list|)
decl_stmt|;
if|if
condition|(
name|removed
operator|==
literal|null
condition|)
block|{
name|removed
operator|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|removed
operator|.
name|add
argument_list|(
name|removedJob
operator|.
name|getLocation
argument_list|()
operator|.
name|getDataFileId
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|metaData
operator|.
name|getRemoveLocationTracker
argument_list|()
operator|.
name|put
argument_list|(
name|tx
argument_list|,
name|logId
argument_list|,
name|removed
argument_list|)
expr_stmt|;
block|}
comment|/**      * Retrieve the scheduled Job's byte blob from the journal.      *      * @param location      *      The location of the KahaAddScheduledJobCommand that originated the Job.      *      * @return a ByteSequence containing the payload of the scheduled Job.      *      * @throws IOException if an error occurs while reading the payload value.      */
specifier|protected
name|ByteSequence
name|getPayload
parameter_list|(
name|Location
name|location
parameter_list|)
throws|throws
name|IOException
block|{
name|KahaAddScheduledJobCommand
name|job
init|=
operator|(
name|KahaAddScheduledJobCommand
operator|)
name|this
operator|.
name|load
argument_list|(
name|location
argument_list|)
decl_stmt|;
name|Buffer
name|payload
init|=
name|job
operator|.
name|getPayload
argument_list|()
decl_stmt|;
return|return
operator|new
name|ByteSequence
argument_list|(
name|payload
operator|.
name|getData
argument_list|()
argument_list|,
name|payload
operator|.
name|getOffset
argument_list|()
argument_list|,
name|payload
operator|.
name|getLength
argument_list|()
argument_list|)
return|;
block|}
specifier|public
name|void
name|readLockIndex
parameter_list|()
block|{
name|this
operator|.
name|indexLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|readUnlockIndex
parameter_list|()
block|{
name|this
operator|.
name|indexLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|writeLockIndex
parameter_list|()
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|writeUnlockIndex
parameter_list|()
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"JobSchedulerStore: "
operator|+
name|getDirectory
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|protected
name|String
name|getPageFileName
parameter_list|()
block|{
return|return
literal|"scheduleDB"
return|;
block|}
annotation|@
name|Override
specifier|protected
name|File
name|getDefaultDataDirectory
parameter_list|()
block|{
return|return
operator|new
name|File
argument_list|(
name|IOHelper
operator|.
name|getDefaultDataDirectory
argument_list|()
argument_list|,
literal|"delayedDB"
argument_list|)
return|;
block|}
specifier|private
class|class
name|MetaDataMarshaller
extends|extends
name|VariableMarshaller
argument_list|<
name|JobSchedulerKahaDBMetaData
argument_list|>
block|{
specifier|private
specifier|final
name|JobSchedulerStoreImpl
name|store
decl_stmt|;
name|MetaDataMarshaller
parameter_list|(
name|JobSchedulerStoreImpl
name|store
parameter_list|)
block|{
name|this
operator|.
name|store
operator|=
name|store
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|JobSchedulerKahaDBMetaData
name|readPayload
parameter_list|(
name|DataInput
name|dataIn
parameter_list|)
throws|throws
name|IOException
block|{
name|JobSchedulerKahaDBMetaData
name|rc
init|=
operator|new
name|JobSchedulerKahaDBMetaData
argument_list|(
name|store
argument_list|)
decl_stmt|;
name|rc
operator|.
name|read
argument_list|(
name|dataIn
argument_list|)
expr_stmt|;
return|return
name|rc
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|writePayload
parameter_list|(
name|JobSchedulerKahaDBMetaData
name|object
parameter_list|,
name|DataOutput
name|dataOut
parameter_list|)
throws|throws
name|IOException
block|{
name|object
operator|.
name|write
argument_list|(
name|dataOut
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Called during index recovery to rebuild the index from the last known good location.  For      * entries that occur before the last known good position we just ignore then and move on.      *      * @param command      *        the command read from the Journal which should be used to update the index.      * @param location      *        the location in the index where the command was read.      * @param inDoubtlocation      *        the location in the index known to be the last time the index was valid.      *      * @throws IOException if an error occurs while recovering the index.      */
specifier|protected
name|void
name|doRecover
parameter_list|(
name|JournalCommand
argument_list|<
name|?
argument_list|>
name|data
parameter_list|,
specifier|final
name|Location
name|location
parameter_list|,
specifier|final
name|Location
name|inDoubtlocation
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|inDoubtlocation
operator|!=
literal|null
operator|&&
name|location
operator|.
name|compareTo
argument_list|(
name|inDoubtlocation
argument_list|)
operator|>=
literal|0
condition|)
block|{
name|process
argument_list|(
name|data
argument_list|,
name|location
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Called during recovery to allow the store to rebuild from scratch.      *      * @param data      *      The command to process, which was read from the Journal.      * @param location      *      The location of the command in the Journal.      *      * @throws IOException if an error occurs during command processing.      */
annotation|@
name|Override
specifier|protected
name|void
name|process
parameter_list|(
name|JournalCommand
argument_list|<
name|?
argument_list|>
name|data
parameter_list|,
specifier|final
name|Location
name|location
parameter_list|)
throws|throws
name|IOException
block|{
name|data
operator|.
name|visit
argument_list|(
operator|new
name|Visitor
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
specifier|final
name|KahaAddScheduledJobCommand
name|command
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|JobSchedulerImpl
name|scheduler
decl_stmt|;
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
try|try
block|{
name|scheduler
operator|=
operator|(
name|JobSchedulerImpl
operator|)
name|getJobScheduler
argument_list|(
name|command
operator|.
name|getScheduler
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|getPageFile
argument_list|()
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|scheduler
operator|.
name|process
argument_list|(
name|tx
argument_list|,
name|command
argument_list|,
name|location
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|processLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
specifier|final
name|KahaRemoveScheduledJobCommand
name|command
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|JobSchedulerImpl
name|scheduler
decl_stmt|;
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
try|try
block|{
name|scheduler
operator|=
operator|(
name|JobSchedulerImpl
operator|)
name|getJobScheduler
argument_list|(
name|command
operator|.
name|getScheduler
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|getPageFile
argument_list|()
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|scheduler
operator|.
name|process
argument_list|(
name|tx
argument_list|,
name|command
argument_list|,
name|location
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|processLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
specifier|final
name|KahaRemoveScheduledJobsCommand
name|command
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|JobSchedulerImpl
name|scheduler
decl_stmt|;
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
try|try
block|{
name|scheduler
operator|=
operator|(
name|JobSchedulerImpl
operator|)
name|getJobScheduler
argument_list|(
name|command
operator|.
name|getScheduler
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|getPageFile
argument_list|()
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|scheduler
operator|.
name|process
argument_list|(
name|tx
argument_list|,
name|command
argument_list|,
name|location
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|processLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
specifier|final
name|KahaRescheduleJobCommand
name|command
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|JobSchedulerImpl
name|scheduler
decl_stmt|;
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
try|try
block|{
name|scheduler
operator|=
operator|(
name|JobSchedulerImpl
operator|)
name|getJobScheduler
argument_list|(
name|command
operator|.
name|getScheduler
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|getPageFile
argument_list|()
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|scheduler
operator|.
name|process
argument_list|(
name|tx
argument_list|,
name|command
argument_list|,
name|location
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|processLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
specifier|final
name|KahaDestroySchedulerCommand
name|command
parameter_list|)
block|{
try|try
block|{
name|removeJobScheduler
argument_list|(
name|command
operator|.
name|getScheduler
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to remove scheduler: {}"
argument_list|,
name|command
operator|.
name|getScheduler
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|processLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|visit
parameter_list|(
name|KahaTraceCommand
name|command
parameter_list|)
block|{
name|processLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
specifier|protected
name|void
name|processLocation
parameter_list|(
specifier|final
name|Location
name|location
parameter_list|)
block|{
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|metaData
operator|.
name|setLastUpdateLocation
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * We recover from the Journal logs as needed to restore the index.      *      * @throws IllegalStateException      * @throws IOException      */
specifier|private
name|void
name|recover
parameter_list|()
throws|throws
name|IllegalStateException
throws|,
name|IOException
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|long
name|start
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|Location
name|lastIndoubtPosition
init|=
name|getRecoveryPosition
argument_list|()
decl_stmt|;
name|Location
name|recoveryPosition
init|=
name|lastIndoubtPosition
decl_stmt|;
if|if
condition|(
name|recoveryPosition
operator|!=
literal|null
condition|)
block|{
name|int
name|redoCounter
init|=
literal|0
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Recovering from the scheduled job journal @"
operator|+
name|recoveryPosition
argument_list|)
expr_stmt|;
while|while
condition|(
name|recoveryPosition
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|JournalCommand
argument_list|<
name|?
argument_list|>
name|message
init|=
name|load
argument_list|(
name|recoveryPosition
argument_list|)
decl_stmt|;
name|metaData
operator|.
name|setLastUpdateLocation
argument_list|(
name|recoveryPosition
argument_list|)
expr_stmt|;
name|doRecover
argument_list|(
name|message
argument_list|,
name|recoveryPosition
argument_list|,
name|lastIndoubtPosition
argument_list|)
expr_stmt|;
name|redoCounter
operator|++
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|failedRecovery
parameter_list|)
block|{
if|if
condition|(
name|isIgnoreMissingJournalfiles
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to recover data at position:"
operator|+
name|recoveryPosition
argument_list|,
name|failedRecovery
argument_list|)
expr_stmt|;
comment|// track this dud location
name|journal
operator|.
name|corruptRecoveryLocation
argument_list|(
name|recoveryPosition
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to recover data at position:"
operator|+
name|recoveryPosition
argument_list|,
name|failedRecovery
argument_list|)
throw|;
block|}
block|}
name|recoveryPosition
operator|=
name|journal
operator|.
name|getNextLocation
argument_list|(
name|recoveryPosition
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
operator|&&
name|redoCounter
operator|%
literal|100000
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"@ {}, {} entries recovered .."
argument_list|,
name|recoveryPosition
argument_list|,
name|redoCounter
argument_list|)
expr_stmt|;
block|}
block|}
name|long
name|end
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Recovery replayed {} operations from the journal in {} seconds."
argument_list|,
name|redoCounter
argument_list|,
operator|(
operator|(
name|end
operator|-
name|start
operator|)
operator|/
literal|1000.0f
operator|)
argument_list|)
expr_stmt|;
block|}
comment|// We may have to undo some index updates.
name|pageFile
operator|.
name|tx
argument_list|()
operator|.
name|execute
argument_list|(
operator|new
name|Transaction
operator|.
name|Closure
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|recoverIndex
argument_list|(
name|tx
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|indexLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|Location
name|getRecoveryPosition
parameter_list|()
throws|throws
name|IOException
block|{
comment|// This loads the first position and we completely rebuild the index if we
comment|// do not override it with some known recovery start location.
name|Location
name|result
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|!
name|isForceRecoverIndex
argument_list|()
condition|)
block|{
if|if
condition|(
name|metaData
operator|.
name|getLastUpdateLocation
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|result
operator|=
name|metaData
operator|.
name|getLastUpdateLocation
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|journal
operator|.
name|getNextLocation
argument_list|(
name|result
argument_list|)
return|;
block|}
specifier|private
name|void
name|recoverIndex
parameter_list|(
name|Transaction
name|tx
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|start
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// It is possible index updates got applied before the journal updates..
comment|// in that case we need to removed references to Jobs that are not in the journal
specifier|final
name|Location
name|lastAppendLocation
init|=
name|journal
operator|.
name|getLastAppendLocation
argument_list|()
decl_stmt|;
name|long
name|undoCounter
init|=
literal|0
decl_stmt|;
comment|// Go through all the jobs in each scheduler and check if any are added after
comment|// the last appended location and remove those.  For now we ignore the update
comment|// location since the scheduled job will update itself after the next fire and
comment|// a new update will replace any existing update.
for|for
control|(
name|Iterator
argument_list|<
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|JobSchedulerImpl
argument_list|>
argument_list|>
name|i
init|=
name|metaData
operator|.
name|getJobSchedulers
argument_list|()
operator|.
name|iterator
argument_list|(
name|tx
argument_list|)
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|JobSchedulerImpl
argument_list|>
name|entry
init|=
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|JobSchedulerImpl
name|scheduler
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|JobLocation
argument_list|>
name|jobLocationIterator
init|=
name|scheduler
operator|.
name|getAllScheduledJobs
argument_list|(
name|tx
argument_list|)
init|;
name|jobLocationIterator
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|JobLocation
name|job
init|=
name|jobLocationIterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|job
operator|.
name|getLocation
argument_list|()
operator|.
name|compareTo
argument_list|(
name|lastAppendLocation
argument_list|)
operator|>=
literal|0
condition|)
block|{
if|if
condition|(
name|scheduler
operator|.
name|removeJobAtTime
argument_list|(
name|tx
argument_list|,
name|job
operator|.
name|getJobId
argument_list|()
argument_list|,
name|job
operator|.
name|getNextTime
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Removed Job past last appened in the journal: {}"
argument_list|,
name|job
operator|.
name|getJobId
argument_list|()
argument_list|)
expr_stmt|;
name|undoCounter
operator|++
expr_stmt|;
block|}
block|}
block|}
block|}
if|if
condition|(
name|undoCounter
operator|>
literal|0
condition|)
block|{
comment|// The rolled back operations are basically in flight journal writes.  To avoid getting
comment|// these the end user should do sync writes to the journal.
name|long
name|end
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Rolled back {} messages from the index in {} seconds."
argument_list|,
name|undoCounter
argument_list|,
operator|(
operator|(
name|end
operator|-
name|start
operator|)
operator|/
literal|1000.0f
operator|)
argument_list|)
expr_stmt|;
name|undoCounter
operator|=
literal|0
expr_stmt|;
block|}
comment|// Now we check for missing and corrupt journal files.
comment|// 1. Collect the set of all referenced journal files based on the Location of the
comment|//    the scheduled jobs and the marked last update field.
name|HashSet
argument_list|<
name|Integer
argument_list|>
name|missingJournalFiles
init|=
operator|new
name|HashSet
argument_list|<
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|JobSchedulerImpl
argument_list|>
argument_list|>
name|i
init|=
name|metaData
operator|.
name|getJobSchedulers
argument_list|()
operator|.
name|iterator
argument_list|(
name|tx
argument_list|)
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|JobSchedulerImpl
argument_list|>
name|entry
init|=
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|JobSchedulerImpl
name|scheduler
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|JobLocation
argument_list|>
name|jobLocationIterator
init|=
name|scheduler
operator|.
name|getAllScheduledJobs
argument_list|(
name|tx
argument_list|)
init|;
name|jobLocationIterator
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|JobLocation
name|job
init|=
name|jobLocationIterator
operator|.
name|next
argument_list|()
decl_stmt|;
name|missingJournalFiles
operator|.
name|add
argument_list|(
name|job
operator|.
name|getLocation
argument_list|()
operator|.
name|getDataFileId
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|job
operator|.
name|getLastUpdate
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|missingJournalFiles
operator|.
name|add
argument_list|(
name|job
operator|.
name|getLastUpdate
argument_list|()
operator|.
name|getDataFileId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// 2. Remove from that set all known data file Id's in the journal and what's left
comment|//    is the missing set which will soon also contain the corrupted set.
name|missingJournalFiles
operator|.
name|removeAll
argument_list|(
name|journal
operator|.
name|getFileMap
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|missingJournalFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Some journal files are missing: {}"
argument_list|,
name|missingJournalFiles
argument_list|)
expr_stmt|;
block|}
comment|// 3. Now check all references in the journal logs for corruption and add any
comment|//    corrupt journal files to the missing set.
name|HashSet
argument_list|<
name|Location
argument_list|>
name|corruptedLocations
init|=
operator|new
name|HashSet
argument_list|<
name|Location
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|isCheckForCorruptJournalFiles
argument_list|()
condition|)
block|{
name|Collection
argument_list|<
name|DataFile
argument_list|>
name|dataFiles
init|=
name|journal
operator|.
name|getFileMap
argument_list|()
operator|.
name|values
argument_list|()
decl_stmt|;
for|for
control|(
name|DataFile
name|dataFile
range|:
name|dataFiles
control|)
block|{
name|int
name|id
init|=
name|dataFile
operator|.
name|getDataFileId
argument_list|()
decl_stmt|;
for|for
control|(
name|long
name|offset
range|:
name|dataFile
operator|.
name|getCorruptedBlocks
argument_list|()
control|)
block|{
name|corruptedLocations
operator|.
name|add
argument_list|(
operator|new
name|Location
argument_list|(
name|id
argument_list|,
operator|(
name|int
operator|)
name|offset
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|corruptedLocations
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found some corrupted data blocks in the journal: {}"
argument_list|,
name|corruptedLocations
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// 4. Now we either fail or we remove all references to missing or corrupt journal
comment|//    files from the various JobSchedulerImpl instances.  We only remove the Job if
comment|//    the initial Add operation is missing when the ignore option is set, the updates
comment|//    could be lost but that's price you pay when ignoring the missing logs.
if|if
condition|(
operator|!
name|missingJournalFiles
operator|.
name|isEmpty
argument_list|()
operator|||
operator|!
name|corruptedLocations
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|isIgnoreMissingJournalfiles
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Detected missing/corrupt journal files."
argument_list|)
throw|;
block|}
comment|// Remove all Jobs that reference an Location that is either missing or corrupt.
name|undoCounter
operator|=
name|removeJobsInMissingOrCorruptJounralFiles
argument_list|(
name|tx
argument_list|,
name|missingJournalFiles
argument_list|,
name|corruptedLocations
argument_list|)
expr_stmt|;
comment|// Clean up the Journal Reference count Map.
name|removeJournalRCForMissingFiles
argument_list|(
name|tx
argument_list|,
name|missingJournalFiles
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|undoCounter
operator|>
literal|0
condition|)
block|{
name|long
name|end
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Detected missing/corrupt journal files.  Dropped {} jobs from the "
operator|+
literal|"index in {} seconds."
argument_list|,
name|undoCounter
argument_list|,
operator|(
operator|(
name|end
operator|-
name|start
operator|)
operator|/
literal|1000.0f
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|removeJournalRCForMissingFiles
parameter_list|(
name|Transaction
name|tx
parameter_list|,
name|Set
argument_list|<
name|Integer
argument_list|>
name|missing
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Integer
argument_list|>
name|matches
init|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|Integer
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|references
init|=
name|metaData
operator|.
name|getJournalRC
argument_list|()
operator|.
name|iterator
argument_list|(
name|tx
argument_list|)
decl_stmt|;
while|while
condition|(
name|references
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|int
name|dataFileId
init|=
name|references
operator|.
name|next
argument_list|()
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|missing
operator|.
name|contains
argument_list|(
name|dataFileId
argument_list|)
condition|)
block|{
name|matches
operator|.
name|add
argument_list|(
name|dataFileId
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|Integer
name|match
range|:
name|matches
control|)
block|{
name|metaData
operator|.
name|getJournalRC
argument_list|()
operator|.
name|remove
argument_list|(
name|tx
argument_list|,
name|match
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|int
name|removeJobsInMissingOrCorruptJounralFiles
parameter_list|(
name|Transaction
name|tx
parameter_list|,
name|Set
argument_list|<
name|Integer
argument_list|>
name|missing
parameter_list|,
name|Set
argument_list|<
name|Location
argument_list|>
name|corrupted
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|removed
init|=
literal|0
decl_stmt|;
comment|// Remove Jobs that reference missing or corrupt files.
comment|// Remove Reference counts to missing or corrupt files.
comment|// Remove and remove command markers to missing or corrupt files.
for|for
control|(
name|Iterator
argument_list|<
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|JobSchedulerImpl
argument_list|>
argument_list|>
name|i
init|=
name|metaData
operator|.
name|getJobSchedulers
argument_list|()
operator|.
name|iterator
argument_list|(
name|tx
argument_list|)
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|JobSchedulerImpl
argument_list|>
name|entry
init|=
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|JobSchedulerImpl
name|scheduler
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|JobLocation
argument_list|>
name|jobLocationIterator
init|=
name|scheduler
operator|.
name|getAllScheduledJobs
argument_list|(
name|tx
argument_list|)
init|;
name|jobLocationIterator
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|JobLocation
name|job
init|=
name|jobLocationIterator
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// Remove all jobs in missing log files.
if|if
condition|(
name|missing
operator|.
name|contains
argument_list|(
name|job
operator|.
name|getLocation
argument_list|()
operator|.
name|getDataFileId
argument_list|()
argument_list|)
condition|)
block|{
name|scheduler
operator|.
name|removeJobAtTime
argument_list|(
name|tx
argument_list|,
name|job
operator|.
name|getJobId
argument_list|()
argument_list|,
name|job
operator|.
name|getNextTime
argument_list|()
argument_list|)
expr_stmt|;
name|removed
operator|++
expr_stmt|;
continue|continue;
block|}
comment|// Remove all jobs in corrupted parts of log files.
if|if
condition|(
name|corrupted
operator|.
name|contains
argument_list|(
name|job
operator|.
name|getLocation
argument_list|()
argument_list|)
condition|)
block|{
name|scheduler
operator|.
name|removeJobAtTime
argument_list|(
name|tx
argument_list|,
name|job
operator|.
name|getJobId
argument_list|()
argument_list|,
name|job
operator|.
name|getNextTime
argument_list|()
argument_list|)
expr_stmt|;
name|removed
operator|++
expr_stmt|;
block|}
block|}
block|}
return|return
name|removed
return|;
block|}
block|}
end_class

end_unit

